//
// At a top level, we have a Facility. A Facility contains Repos.

// A Facility will have Capacities that define the amount of resource that is available to that Facility.
// At the moment, we only have a count of the compute resource that is available to the Facility. This is defined as
// a count of the number of compute servers from each Cluster.

// We only currently associate storage with a Repo.
// We have different classes of storage (science-data, group, etc). and each Repo may have none or many of each
// type. We want to keep tabs of the Quota ie the Repo's storage Capacity.
// We keep the permissions model of the storage with an Access Class and associate them to Volumes. It is the Volumes
// that are associated with the Repos.

// is this backwards? on one hand we have the Facility with a total Capacity, and we provide percentage Allocations of compute to each Repo; but with storage we have a an absolute quota per volume in a Repo; but don't actually keep anything yet in the Facility regarding storage.

db.getSiblingDB("iris").facilities.createIndex({"name": 1}, unique=true)
// Facilities have compute classes and storage classes associated with them.


db.getSiblingDB("iris").facilities.insertOne({
  "name" : "LCLS",
  "resources": ["compute", "storage"],
  "czars": [ "lcls-pcdsdata"], // set primary uid on all volumes
  "access_class": [ "lcls-pcdsmgr" ], // set primary gid on all volumes
  "repo_script": "/cds/group/lcls/scripts/run_script_on_repo_creation.sh", // Automatic scripts that will be run on repo creation by the backend
  "user_script": "/cds/group/lcls/scripts/run_script_on_user_creation.sh", // Automatic scripts that will be run on user creation by the backend
})

db.getSiblingDB("iris").facilities.insertOne({
  "name" : "CryoEM",
  "resources": ["compute", "storage"],
  "czars": [ "cryo-daq"], // set primary uid on all volumes
  "access_class": [ "cryo-data" ] // set primary gid on all volumes
})

db.getSiblingDB("iris").facilities.insertOne({
  "name" : "Suncat",
  "resources": ["compute", "storage"],
  "czars": [ "johannes"], // set primary uid on all volumes
  "access_class": [ ] // set primary gid on all volumes
})




// define a capacity to be the actual resources provided to each facility
// keep a count of the number of units of each type of cluster - this shoudl make it simple for admins to add new resrouces to each facility

db.getSiblingDB("iris").capacity.createIndex({"facility": 1, "start": 1})


db.getSiblingDB("iris").capacity.insertOne({
  "facility": "LCLS",
  "start": ISODate("2020-01-01T00:00:00-07:00"),
  "end": ISODate("2021-05-01T00:00:00-07:00"),
  "clusters": [
    {
      "name": "rome-b050",
      "slachours": 23.5, // Can this be computed from the cluster itself?
    },
    {
      "name": "milan-srcf",
      "slachours": 10.0
    }
  ],
  "storage": [
    {
      "name": "science-data",
      "gigabytes": 1000000,
      "inodes": 100000
    },
    {
      "name": "group",
      "gigabytes": 100000,
      "inodes": 10000
    }
  ]
})

db.getSiblingDB("iris").capacity.insertOne({
  "facility": "LCLS",
  "start": ISODate("2021-05-01T00:00:00-07:00"),
  "end": ISODate("2100-01-01T00:00:00Z"), // Distant future
  "clusters": [
    {
      "name": "rome-b050",
      "slachours": 23.5, // Can this be computed from the cluster itself?
    },
    {
      "name": "milan-srcf",
      "slachours": 10.0
    },
    {
      "name": "ampt",
      "slachours": 1.0
    },
    {
      "name": "psana",
      "slachours": 100.0
    }
  ],
  "storage": [
    {
      "name": "science-data",
      "gigabytes": 40000000,
      "inodes": 200000
    },
    {
      "name": "group",
      "gigabytes": 600000,
      "inodes": 20000
    }
  ]
})


db.getSiblingDB("iris").cluster.createIndex({"name": 1}, unique=true)

db.getSiblingDB("iris").cluster.insertOne({
  "name": "rome-b050",
  "nodecpucount": 128,
  "nodecpucountdivisor": 64, //?? sockets?
  "nodememgb": 512,
  "chargefactor": 0.8,
  "nodecpusmt": 1, // threads per core
  "members": [ "rome0001", "rome0002","rome0003","rome0004","rome0005" ] // perhaps use regex?
})


db.getSiblingDB("iris").cluster.insertOne({
  "name": "milan-srcf",
  "nodecpucount": 16,
  "nodecpucountdivisor": 16, //??
  "nodememgb": 512,
  "chargefactor": 0.8,
  "nodecpusmt": 1, // threads per core
  "members": [ "milan0001", "milan0002","milan0003","milan0004","milan0005" ]
})

db.getSiblingDB("iris").cluster.insertOne({
  "name": "ampt",
  "nodecpucount": 128,
  "nodecpucountdivisor": 16, //??
  "nodememgb": 1024,
  "chargefactor": 0.8,
  "nodecpusmt": 2, // threads per core
  "nodegpucount": 4,
  "nodegpumemgb": 40,
  "members": [ "ampt001", "ampt002","ampt003","ampt004","ampt005" ]
})

db.getSiblingDB("iris").cluster.insertOne({
  "name": "psana",
  "nodecpucount": 16,
  "nodecpucountdivisor": 16, //??
  "nodememgb": 512,
  "chargefactor": 0.8,
  "nodecpusmt": 1, // threads per core
  "members": [ ]
})

// Too lazy to create all the cluster members for psana
for(c=1200;c<1600;c++) {   db.getSiblingDB("iris").cluster.updateOne({"name": "psana"}, {"$addToSet": {"members": "psana"+c}})}

db.getSiblingDB("iris").repos.createIndex({"name": 1}, unique=true)
db.getSiblingDB("iris").repos.createIndex({"leader": 1}) // For performance
db.getSiblingDB("iris").repos.insertOne({
  "name": "cxi12345",
  "facility": "LCLS",
  "principal": "aquila",
  "leaders": [ "snelson" ],
  "users": [ "aquila", "mcbrowne", "snelson", "tmalla", "yanwen", "mshankar" ],
  "access_groups": []
})

db.getSiblingDB("iris").repos.insertOne({
  "name": "CS14",
  "facility": "CryoEM",
  "principal": "ytl",
  "leaders": [],
  "users": [ "cszhang" ],
  "access_groups": [ "CS14" ]

})
db.getSiblingDB("iris").repos.insertOne({
  "name": "CA104",
  "facility": "CryoEM",
  "principal": "mshankar",
  "leaders": [ "ytl" ],
  "users": [ ],
  "access_groups": [ "CA104" ]
})


// Of course, user has other information like full name, email etc. Maybe some of that comes from inCommon?
db.getSiblingDB("iris").users.createIndex({"username": 1}, unique=true)
db.getSiblingDB("iris").users.createIndex({"uidnumber": 1}, unique=true)
db.getSiblingDB("iris").users.createIndex({"eppns": 1}, {unique: true, partialFilterExpression: { eppns: { $type: "array" }}})
db.getSiblingDB("iris").users.insertOne({ "username": "aquila", "uidnumber": 123, "eppns": [ "aquila@slac.stanford.edu" ] })
db.getSiblingDB("iris").users.insertOne({ "username": "mcbrowne", "uidnumber": 124, "eppns": [ "mcbrowne@slac.stanford.edu" ] })
db.getSiblingDB("iris").users.insertOne({ "username": "snelson", "uidnumber": 125, "eppns": [ "snelson@slac.stanford.edu" ] })
db.getSiblingDB("iris").users.insertOne({ "username": "tmalla", "uidnumber": 126, "eppns": [ "tmalla@slac.stanford.edu" ] })
db.getSiblingDB("iris").users.insertOne({ "username": "yanwen", "uidnumber": 127, "eppns": [ "yanwen@slac.stanford.edu" ] })
db.getSiblingDB("iris").users.insertOne({ "username": "mshankar", "uidnumber": 128, "eppns": [ "mshankar@slac.stanford.edu", "muralis@stanford.edu" ] })
db.getSiblingDB("iris").users.insertOne({ "username": "ytl", "uidnumber": 129, "eppns": [ "ytl@slac.stanford.edu", "yee379@stanford.edu" ] })
db.getSiblingDB("iris").users.insertOne({ "username": "wilko", "uidnumber": 130, "eppns": [ "wilko@slac.stanford.edu" ] })


db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "RepoMembership", "username" : "wilko", "reponame" : "cxi12345"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "RepoMembership", "username" : "wilko", "reponame" : "CA104"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "RepoMembership", "username" : "mshankar", "reponame" : "CA104"})
// Two people requesting the same repo/facility
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "NewRepo", "username" : "wilko",    "reponame" : "cxi23456"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "NewRepo", "username" : "mshankar", "reponame" : "cxi23456"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "NewFacility", "username" : "wilko",    "facilityname" : "RUBIN"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "NewFacility", "username" : "mshankar", "facilityname" : "RUBIN"})

db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "UserAccount", "eppn" : "paul@stanford.edu", "preferredUserName": "paul", "reponame" : "cxi12345", "facilityname" : "LCLS"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "UserAccount", "eppn" : "george@stanford.edu", "preferredUserName": "george", "reponame" : "cxi12345", "facilityname" : "LCLS"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "UserAccount", "eppn" : "john@stanford.edu", "preferredUserName": "john", "reponame" : "cxi12345", "facilityname" : "LCLS"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "UserAccount", "eppn" : "ringo@stanford.edu", "preferredUserName": "ringo", "reponame" : "cxi12345", "facilityname" : "LCLS"})
// These are requests for user account whose username already exists in the system.
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "UserAccount", "eppn" : "wilko@stanford.edu", "preferredUserName": "wilko", "reponame" : "cxi12345", "facilityname" : "LCLS"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "UserAccount", "eppn" : "mshankar@stanford.edu", "preferredUserName": "mshankar", "reponame" : "cxi12345", "facilityname" : "LCLS"})
db.getSiblingDB("iris").requests.insertOne({ "reqtype" : "UserAccount", "eppn" : "ytl@stanford.edu", "preferredUserName": "ytl", "reponame" : "cxi12345", "facilityname" : "LCLS"})



// an access class defines an abstraiton of access to some data. as such, by itself it merely defines essentially just a gidnumber. these shoudl be associated with eitehr: (note that all three can apply to all related storage)
// 1) facility (to have all data under that facility with say the same primiarly group id defined in the access group)
// 2) to a repo; so that the repo has this gid
// 3) to a volume so that only that volume has that gid

db.getSiblingDB("iris").access_groups.createIndex({"name": 1}, unique=true)
db.getSiblingDB("iris").access_groups.createIndex({"gid_number": 1}, unique=true)

// facility service account; use the gid as default and uids from members as primary owners
db.getSiblingDB("iris").access_class.insertOne({"name": "lcls-pcdsmgr", "gid_number": 808080, "members": [ "pcdmgr" ]})

// no members means nothing special - use the principal, leaders and users for this group
db.getSiblingDB("iris").access_class.insertOne({"name": "cxi12345", "gid_number": 12345, "members": null})


db.getSiblingDB("iris").access_class.insertOne({"name": "cryo-data", "gid_number": 6363, "members": [ "cryo-daq"]})
db.getSiblingDB("iris").access_class.insertOne({"name": "CS14", "gid_number": 8393, "members": []})
db.getSiblingDB("iris").access_class.insertOne({"name": "CA104", "gid_number": 8343, "members": []})



// ?? do we need like a basePath Prefix definition in the Facility level?
// a Volume merely defines some storage somewhere which is associated with teh access class to deteremine access permissions (gids)
db.getSiblingDB("iris").volumes.insertOne({
  "facility": "LCLS",
  "name": "cxi12345",
  "type": "science-data",
  "access_class": [ "cxi12345" ],
  "path": "/sdf/data/lcls/cxi/cxi/123456"
})
db.getSiblingDB("iris").volumes.insertOne({
  "facility": "LCLS",
  "name": "cxi12345",
  "type": "group",
  "access_class": [ "cxi12345" ],
  "path": "/sdf/group/lcls/cxi/cxi/123456"
})


db.getSiblingDB("iris").volumes.insertOne({
  "facility": "LCLS",
  "name": "20211107-CS14",
  "type": "science-data",
  "access_class": [ "CS14" ],
  "path": "/sdf/data/cryoem/202111/20211107-CS14_TEM4"
})
db.getSiblingDB("iris").volumes.insertOne({
  "facility": "LCLS",
  "name": "20221112_CA104",
  "type": "science-data",
  "access_class": [ "CA104" ],
  "path": "/sdf/data/cryoem/202111/20221112_CA104_TEMBETA"
})



// a 'storage' allocation defines all the volumes for that repo
// the key of each volume is the 'type' of volume defined above (bit suplurfuous perhaps)
// as the quota of each volume can change, we keep the Volume as a separate document and use this allocation document
// as the thing to keep upto date. we use 'active' as a crude of of determine the most upto date version.
// ?? how to deal with stranded/orphaned volumes?

db.getSiblingDB("iris").allocations.createIndex({"repo": 1, "facility": 1, "resource": 1, "start": -1}, unique=true)


db.getSiblingDB("iris").allocations.insertOne({
  "facility": "LCLS",
  "resource": "storage",
  "repo": "cxi12345",
  "active": true,
  "start": ISODate("2021-05-01T00:00:00-07:00"),
  "end": ISODate("2100-01-01T00:00:00Z"), // Distant future
  "volumes": {
    "science-data": [
      {
        "name": "cxi12345",
        "gigabytes": 5544, // gb
        "inodes": 4455
      }
    ],
    "group": [
      {
        "name": "cxi12345",
        "gigabytes": 1000,
        "inodes": 100
      }
    ]
  }
})



db.getSiblingDB("iris").allocations.insertOne({
  "facility": "CryoEM",
  "resource": "storage",
  "repo": "CS14",
  "active": true,
  "start": ISODate("2021-05-01T00:00:00-07:00"),
  "end": ISODate("2100-01-01T00:00:00Z"), // Distant future
  "volumes": {
    "science-data": [
      {
        "name": "20211107-CS14",
        "gigabytes": 2000,
        "inodes": 20000
      }
    ]
  }
})

db.getSiblingDB("iris").allocations.insertOne({
  "facility": "CryoEM",
  "resource": "storage",
  "repo": "CA104",
  "active": true,
  "start": ISODate("2021-05-01T00:00:00-07:00"),
  "end": ISODate("2100-01-01T00:00:00Z"), // Distant future
  "volumes": {
    "science-data": [
      {
        "name": "20221112_CA104",
        "gigabytes": 2000,
        "inodes": 20000
      }
    ]
  }
})


// compute allocations
// in terms of a compute quota; we assume that slachours already considers things like cpu/gpu and has the
// calculated weights required for varying cluster performances.
// do we want to narrow down specific allocations per partition? the current schema only considers the qoses for the repo - is this sufficient to do everythign we want? how does this map to a partition?

db.getSiblingDB("iris").allocations.insertOne({
  "facility": "LCLS",
  "resource": "compute",
  "repo": "cxi12345",
  "active": true,
  "start": ISODate("2021-05-01T00:00:00-07:00"),
  "end": ISODate("2100-01-01T00:00:00Z"), // Distant future
  "qoses": [
    {
      "name": "cxi12345",
      "slachours": 500,
      "chargefactor": 0.7765
    },
    {
      "name": "cxi12345-priority",
      "slachours": 500,
      "chargefactor": 1.25
    }
  ]
})

db.getSiblingDB("iris").allocations.insertOne({
  "facility": "LCLS",
  "resource": "compute",
  "repo": "cxi12345",
  "active": true,
  "start": ISODate("2020-05-01T00:00:00-07:00"), // Last years allocations
  "end": ISODate("2020-12-31T00:00:00Z"),
  "qoses": [
    {
      "name": "cxi12345",
      "slachours": 100000,
      "chargefactor": 1.0
    },
    {
      "name": "cxi12345-priority",
      "slachours": 1000,
      "chargefactor": 1.25
    }
  ]
})





// usage collection to store information about post processed units of resources that have been consumed by the Repo.
// keep the data in a raw format to reduce the amount of processing to get the data to teh client. would tehre be limits to teh size of the data as a result of keeping it like this?
db.getSiblingDB("iris").usage.insertOne({
  "facility": "LCLS",
  "resource": "storage",
  "repo": "cxi12345",
  "name": "cxi12345",
  "class": "science-data",
  "history": [
    ["20220101",56320,3456], // date, gigabutes, inodes
    ["20220102",56330,3452], // date, gigabutes, inodes
    ["20220103",57530,3552], // date, gigabutes, inodes
  ]
})


db.getSiblingDB("iris").usage.insertOne({
  "facility": "LCLS",
  "resource": "compute",
  "repo": "cxi12345",
  "name": "cxi12345",
  "history": [
    ["20220101",1202], // date, slachours
    ["20220102",1842], // date, slachours
    ["20220103",2349], // date, slachours
  ]
})




// Jobs have lots of information from SLURM in addition to the final mapping into repo, year and resource name.
db.getSiblingDB("iris").jobs.createIndex({"jobId": 1, "startTs": 1, "computeId": 1}, unique=true)
db.getSiblingDB("iris").jobs.createIndex({"repo": 1, "year": -1, "resource": 1}) // Performance index

// We cache the compute and storage allocation usage in the usagecache collections
db.getSiblingDB("iris").computeusagecache.createIndex({"allocationId": 1, "qos": 1}, unique=true)
db.getSiblingDB("iris").storageusagecache.createIndex({"allocationId": 1, "volume": 1}, unique=true)

db.getSiblingDB("iris").diskusage.createIndex({"facility": 1, "resource": 1, "year": -1, "repo": 1, "date": 1}, unique=true)
for(i=0;i<75;i++) {
  db.getSiblingDB("iris").diskusage.insertOne({
    "facility": "LCLS",
    "resource": "data",
    "year": 2022,
    "repo": "cxi12345",
    "folder": "/reg/data/ana01/cxi/cxi12345",
    "storage": 56320,
    "inodes": 3456,
    "date": new Date(1640995200000 + i*86400*1000)
  })
  db.getSiblingDB("iris").diskusage.insertOne({
    "facility": "LCLS",
    "resource": "scratch",
    "year": 2022,
    "repo": "cxi12345",
    "folder": "/reg/scratch/ana01/cxi/cxi12345",
    "storage": 56320,
    "inodes": 100000000,
    "date": new Date(1640995200000 + i*86400*1000)
  })
}
